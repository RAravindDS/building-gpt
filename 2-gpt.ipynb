{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "\n",
    "# In previous the 8 tokens are not talking to each other, we used to biagram to predict next word using n-1 word \n",
    "## so here our aim make this tokes talks with each other \n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 2 \n",
    "x = torch.randn(B, T, C) \n",
    "x.shape\n",
    "\n",
    "\n",
    "## for this we can calculate the average of previuous numbers like if you are in 5th element you can calculate average for first 5 element \n",
    "## [0, 1, 2, 3, 4], you are in fifth element so the average is 2.0 and the current element is 5 the average can convey some of the information \n",
    "## of previous element. Let's try to achieve this in code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1.0\n",
      "[1, 2]\n",
      "1.5\n",
      "[1, 2, 3]\n",
      "2.0\n",
      "[1, 2, 3, 4]\n",
      "2.5\n",
      "[1, 2, 3, 4, 5]\n",
      "3.0\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "3.5\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "4.0\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "4.5\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "## averaging until current element to get the history of previous elements \n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8 , 9]\n",
    "\n",
    "for i in range(len(a)): \n",
    "    avg = sum(a[:i+1]) / len(a[:i+1])\n",
    "    print(a[:i+1])\n",
    "    print(avg)\n",
    "\n",
    "\n",
    "## Here we are averaging the information, but this is very inefficient manner because we need to do this for batching so 2 for loop may come \n",
    "\n",
    "\n",
    "xbow = torch.zeros( (B, T, C))  # Batch size, tensor lenght, channels \n",
    "for b in range(B): # Because we need to do the average for all the batches \n",
    "    for t in range(T): ## we are iterating to the ith batch \n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "\n",
    "\n",
    "## In-efficient loop here :) You can check by comparing x[0] and xbow[0]\n",
    "\n",
    "## we can do this more efficient by using matrix multiplications by using tril (triangular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = torch.tril(torch.ones(T, T)) \n",
    "wei = wei / wei.sum(1, keepdim=True) \n",
    "\n",
    "xbow2 = wei @ x # (T, T) @ (B, T, C)  # this is batched matrix multiply (this is more efficient)\n",
    "# compare xbow1 and xbow2 (both are same only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's re-write in some more way \n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim =-1)\n",
    "wei = wei @ x \n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1.0\n",
      "[1, 2]\n",
      "1.5\n",
      "[1, 2, 3]\n",
      "2.0\n",
      "[1, 2, 3, 4]\n",
      "2.5\n",
      "[1, 2, 3, 4, 5]\n",
      "3.0\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "3.5\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "4.0\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "4.5\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "5.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0+ 1+2+3+4) / 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
